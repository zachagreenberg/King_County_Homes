{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition of a Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the previous three models for consideration, I decided to go back and take a look at the possibility of adding a fourth model. I wanted to see if I can use a model with Deep Neural Networks for a more realistic assessment of housing prices. I was able to reach my goal of coming under $200000, but I believe that I can do even better with the use of a neural network. I am going to bring in my cleaned data so that I can go right into the modeling process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing in the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in the cleaned\n",
    "infile = open(\"Data/cleaned_data.pickle\",'rb')\n",
    "df = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>log_yard</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2390</td>\n",
       "      <td>8.969287</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1070</td>\n",
       "      <td>2370</td>\n",
       "      <td>8.250620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>9.105868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>9.419628</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2250</td>\n",
       "      <td>8.318986</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  bedrooms  bathrooms  sqft_living  floors  waterfront  \\\n",
       "0   365000.0       4.0        2.0       2070.0     2.0           0   \n",
       "1   865000.0       5.0        3.0       2900.0     1.0           0   \n",
       "2  1038000.0       4.0        2.0       3770.0     2.0           0   \n",
       "3  1490000.0       3.0        4.0       4560.0     2.0           0   \n",
       "4   711000.0       3.0        2.0       2550.0     2.0           0   \n",
       "\n",
       "   sqft_above  sqft_basement  sqft_living15  log_yard  ...  zipcode_98146  \\\n",
       "0      2070.0              0           2390  8.969287  ...              0   \n",
       "1      1830.0           1070           2370  8.250620  ...              0   \n",
       "2      3770.0              0           3710  9.105868  ...              0   \n",
       "3      4560.0              0           4050  9.419628  ...              0   \n",
       "4      2550.0              0           2250  8.318986  ...              0   \n",
       "\n",
       "   zipcode_98148  zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98178  zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0              0  \n",
       "1              0              0              0              0  \n",
       "2              0              0              0              0  \n",
       "3              0              0              0              0  \n",
       "4              0              0              0              0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the dependent variable\n",
    "dvariables = df.iloc[:, 1:]\n",
    "\n",
    "#this here will become the SHAPE variable in the function below\n",
    "number_of_columns = len(dvariables.columns)\n",
    "\n",
    "#isolating the target variable\n",
    "target = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing train test split\n",
    "X_fulltrain, X_fulltest, y_fulltrain, y_fulltest = train_test_split(dvariables, target, random_state = 42, test_size = .2)\n",
    "\n",
    "#splitting again for a validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_fulltrain, y_fulltrain, random_state = 42, test_size = .2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'adam', num_layers = 1, activation = 'relu', neurons = 50, drop_out= .2, input_shape = 106, learning_rate = .003):\n",
    "    \"\"\"This function takes an optimizer, number of layers, and input_shape. It will create\n",
    "    and compile the model so that it can be ready to be fit in the next step.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = (input_shape,)))\n",
    "    for layer in range(num_layers):\n",
    "        model.add(keras.layers.Dense(neurons, activation = activation))\n",
    "    #This dropout should hopefully be preventing overfitting\n",
    "    model.add(keras.layers.Dropout(drop_out))\n",
    "    model.add(keras.layers.Activation(activation))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer, loss = 'mse', metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = create_model(num_layers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 298951081984.0000 - mse: 298951081984.0000 - val_loss: 81999896576.0000 - val_mse: 81999896576.0000\n",
      "Epoch 2/50\n",
      "346/346 [==============================] - 0s 733us/step - loss: 77919322112.0000 - mse: 77919322112.0000 - val_loss: 75530444800.0000 - val_mse: 75530444800.0000\n",
      "Epoch 3/50\n",
      "346/346 [==============================] - 0s 730us/step - loss: 77944242176.0000 - mse: 77944242176.0000 - val_loss: 75161092096.0000 - val_mse: 75161092096.0000\n",
      "Epoch 4/50\n",
      "346/346 [==============================] - 0s 740us/step - loss: 76925247488.0000 - mse: 76925247488.0000 - val_loss: 74690510848.0000 - val_mse: 74690510848.0000\n",
      "Epoch 5/50\n",
      "346/346 [==============================] - 0s 711us/step - loss: 77814906880.0000 - mse: 77814906880.0000 - val_loss: 74811293696.0000 - val_mse: 74811293696.0000\n",
      "Epoch 6/50\n",
      "346/346 [==============================] - 0s 682us/step - loss: 77946683392.0000 - mse: 77946683392.0000 - val_loss: 74363469824.0000 - val_mse: 74363469824.0000\n",
      "Epoch 7/50\n",
      "346/346 [==============================] - 0s 696us/step - loss: 77555834880.0000 - mse: 77555834880.0000 - val_loss: 74050265088.0000 - val_mse: 74050265088.0000\n",
      "Epoch 8/50\n",
      "346/346 [==============================] - 0s 716us/step - loss: 76851011584.0000 - mse: 76851011584.0000 - val_loss: 73815777280.0000 - val_mse: 73815777280.0000\n",
      "Epoch 9/50\n",
      "346/346 [==============================] - 0s 680us/step - loss: 76698238976.0000 - mse: 76698238976.0000 - val_loss: 73649602560.0000 - val_mse: 73649602560.0000\n",
      "Epoch 10/50\n",
      "346/346 [==============================] - 0s 739us/step - loss: 76954042368.0000 - mse: 76954042368.0000 - val_loss: 73586794496.0000 - val_mse: 73586794496.0000\n",
      "Epoch 11/50\n",
      "346/346 [==============================] - 0s 712us/step - loss: 76171444224.0000 - mse: 76171444224.0000 - val_loss: 73884172288.0000 - val_mse: 73884172288.0000\n",
      "Epoch 12/50\n",
      "346/346 [==============================] - 0s 679us/step - loss: 76411691008.0000 - mse: 76411691008.0000 - val_loss: 73330589696.0000 - val_mse: 73330589696.0000\n",
      "Epoch 13/50\n",
      "346/346 [==============================] - 0s 706us/step - loss: 76963528704.0000 - mse: 76963528704.0000 - val_loss: 73790611456.0000 - val_mse: 73790611456.0000\n",
      "Epoch 14/50\n",
      "346/346 [==============================] - 0s 686us/step - loss: 76274360320.0000 - mse: 76274360320.0000 - val_loss: 73266241536.0000 - val_mse: 73266241536.0000\n",
      "Epoch 15/50\n",
      "346/346 [==============================] - 0s 688us/step - loss: 76812288000.0000 - mse: 76812288000.0000 - val_loss: 73129058304.0000 - val_mse: 73129058304.0000\n",
      "Epoch 16/50\n",
      "346/346 [==============================] - 0s 701us/step - loss: 75561451520.0000 - mse: 75561451520.0000 - val_loss: 72846336000.0000 - val_mse: 72846336000.0000\n",
      "Epoch 17/50\n",
      "346/346 [==============================] - 0s 686us/step - loss: 76037685248.0000 - mse: 76037685248.0000 - val_loss: 72707932160.0000 - val_mse: 72707932160.0000\n",
      "Epoch 18/50\n",
      "346/346 [==============================] - 0s 683us/step - loss: 76308250624.0000 - mse: 76308250624.0000 - val_loss: 72944467968.0000 - val_mse: 72944467968.0000\n",
      "Epoch 19/50\n",
      "346/346 [==============================] - 0s 695us/step - loss: 75703549952.0000 - mse: 75703549952.0000 - val_loss: 72877350912.0000 - val_mse: 72877350912.0000\n",
      "Epoch 20/50\n",
      "346/346 [==============================] - 0s 690us/step - loss: 76019277824.0000 - mse: 76019277824.0000 - val_loss: 72331853824.0000 - val_mse: 72331853824.0000\n",
      "Epoch 21/50\n",
      "346/346 [==============================] - 0s 688us/step - loss: 75565973504.0000 - mse: 75565973504.0000 - val_loss: 72220082176.0000 - val_mse: 72220082176.0000\n",
      "Epoch 22/50\n",
      "346/346 [==============================] - 0s 696us/step - loss: 75926929408.0000 - mse: 75926929408.0000 - val_loss: 72323055616.0000 - val_mse: 72323055616.0000\n",
      "Epoch 23/50\n",
      "346/346 [==============================] - 0s 689us/step - loss: 74884792320.0000 - mse: 74884792320.0000 - val_loss: 72323194880.0000 - val_mse: 72323194880.0000\n",
      "Epoch 24/50\n",
      "346/346 [==============================] - 0s 690us/step - loss: 75434795008.0000 - mse: 75434795008.0000 - val_loss: 71754145792.0000 - val_mse: 71754145792.0000\n",
      "Epoch 25/50\n",
      "346/346 [==============================] - 0s 690us/step - loss: 74324819968.0000 - mse: 74324819968.0000 - val_loss: 71643627520.0000 - val_mse: 71643627520.0000\n",
      "Epoch 26/50\n",
      "346/346 [==============================] - 0s 701us/step - loss: 74047012864.0000 - mse: 74047012864.0000 - val_loss: 72396824576.0000 - val_mse: 72396824576.0000\n",
      "Epoch 27/50\n",
      "346/346 [==============================] - 0s 693us/step - loss: 75150680064.0000 - mse: 75150680064.0000 - val_loss: 71832682496.0000 - val_mse: 71832682496.0000\n",
      "Epoch 28/50\n",
      "346/346 [==============================] - 0s 714us/step - loss: 74277462016.0000 - mse: 74277462016.0000 - val_loss: 71302578176.0000 - val_mse: 71302578176.0000\n",
      "Epoch 29/50\n",
      "346/346 [==============================] - 0s 694us/step - loss: 73796165632.0000 - mse: 73796165632.0000 - val_loss: 71144579072.0000 - val_mse: 71144579072.0000\n",
      "Epoch 30/50\n",
      "346/346 [==============================] - 0s 687us/step - loss: 75198971904.0000 - mse: 75198971904.0000 - val_loss: 70970064896.0000 - val_mse: 70970064896.0000\n",
      "Epoch 31/50\n",
      "346/346 [==============================] - 0s 691us/step - loss: 75319255040.0000 - mse: 75319255040.0000 - val_loss: 72076877824.0000 - val_mse: 72076877824.0000\n",
      "Epoch 32/50\n",
      "346/346 [==============================] - 0s 725us/step - loss: 74031505408.0000 - mse: 74031505408.0000 - val_loss: 70690521088.0000 - val_mse: 70690521088.0000\n",
      "Epoch 33/50\n",
      "346/346 [==============================] - 0s 689us/step - loss: 76020547584.0000 - mse: 76020547584.0000 - val_loss: 71315922944.0000 - val_mse: 71315922944.0000\n",
      "Epoch 34/50\n",
      "346/346 [==============================] - 0s 724us/step - loss: 74231693312.0000 - mse: 74231693312.0000 - val_loss: 70952255488.0000 - val_mse: 70952255488.0000\n",
      "Epoch 35/50\n",
      "346/346 [==============================] - 0s 684us/step - loss: 75459944448.0000 - mse: 75459944448.0000 - val_loss: 70490660864.0000 - val_mse: 70490660864.0000\n",
      "Epoch 36/50\n",
      "346/346 [==============================] - 0s 713us/step - loss: 73694691328.0000 - mse: 73694691328.0000 - val_loss: 70497779712.0000 - val_mse: 70497779712.0000\n",
      "Epoch 37/50\n",
      "346/346 [==============================] - 0s 691us/step - loss: 72662016000.0000 - mse: 72662016000.0000 - val_loss: 70578913280.0000 - val_mse: 70578913280.0000\n",
      "Epoch 38/50\n",
      "346/346 [==============================] - 0s 688us/step - loss: 73921765376.0000 - mse: 73921765376.0000 - val_loss: 70003392512.0000 - val_mse: 70003392512.0000\n",
      "Epoch 39/50\n",
      "346/346 [==============================] - 0s 682us/step - loss: 74364485632.0000 - mse: 74364485632.0000 - val_loss: 69957140480.0000 - val_mse: 69957140480.0000\n",
      "Epoch 40/50\n",
      "346/346 [==============================] - 0s 721us/step - loss: 73186254848.0000 - mse: 73186254848.0000 - val_loss: 69771059200.0000 - val_mse: 69771059200.0000\n",
      "Epoch 41/50\n",
      "346/346 [==============================] - 0s 702us/step - loss: 72356175872.0000 - mse: 72356175872.0000 - val_loss: 69939789824.0000 - val_mse: 69939789824.0000\n",
      "Epoch 42/50\n",
      "346/346 [==============================] - 0s 733us/step - loss: 72160706560.0000 - mse: 72160706560.0000 - val_loss: 70084993024.0000 - val_mse: 70084993024.0000\n",
      "Epoch 43/50\n",
      "346/346 [==============================] - 0s 713us/step - loss: 74058547200.0000 - mse: 74058547200.0000 - val_loss: 70129369088.0000 - val_mse: 70129369088.0000\n",
      "Epoch 44/50\n",
      "346/346 [==============================] - 0s 691us/step - loss: 73404104704.0000 - mse: 73404104704.0000 - val_loss: 69151318016.0000 - val_mse: 69151318016.0000\n",
      "Epoch 45/50\n",
      "346/346 [==============================] - 0s 681us/step - loss: 73800679424.0000 - mse: 73800679424.0000 - val_loss: 69226446848.0000 - val_mse: 69226446848.0000\n",
      "Epoch 46/50\n",
      "346/346 [==============================] - 0s 686us/step - loss: 73810903040.0000 - mse: 73810903040.0000 - val_loss: 68956610560.0000 - val_mse: 68956610560.0000\n",
      "Epoch 47/50\n",
      "346/346 [==============================] - 0s 690us/step - loss: 72461418496.0000 - mse: 72461418496.0000 - val_loss: 68900061184.0000 - val_mse: 68900061184.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "346/346 [==============================] - 0s 721us/step - loss: 73642082304.0000 - mse: 73642082304.0000 - val_loss: 68752277504.0000 - val_mse: 68752277504.0000\n",
      "Epoch 49/50\n",
      "346/346 [==============================] - 0s 666us/step - loss: 73345687552.0000 - mse: 73345687552.0000 - val_loss: 68846444544.0000 - val_mse: 68846444544.0000\n",
      "Epoch 50/50\n",
      "346/346 [==============================] - 0s 672us/step - loss: 72900689920.0000 - mse: 72900689920.0000 - val_loss: 68826398720.0000 - val_mse: 68826398720.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting the model\n",
    "history = model_1.fit(X_train, y_train, epochs = 50, \n",
    "                      #utilizing our validation set to test/prevent overfitting\n",
    "                      validation_data = (X_valid, y_valid)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at Epoch 50:\n",
      "\n",
      "loss:72900689920.0\n",
      "\n",
      "mse:72900689920.0\n",
      "\n",
      "val_loss:68826398720.0\n",
      "\n",
      "val_mse:68826398720.0\n",
      "\n",
      "RMSE :262347.85823406297\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation at Epoch 50:\\n')\n",
    "for key in history.history:\n",
    "    print(key + ':' + str(history.history[key][-1]) + '\\n')\n",
    "\n",
    "print('RMSE :' + str(np.sqrt(history.history['val_mse'][-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see here that the train set and validation set have come very close to one another. In terms of the actual metric the model has not crossed the threshold of the goal RMSE. For now I am led to believe that the original chosen model shows the most promise. Nevertheless I will continue on an try to lower the error by tinkering manually with the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an attempt at improvement, I am going to try another model with more layers to see how that would compare to the first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am increasing the number of layers in this model\n",
    "model_2 = create_model(num_layers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 123672608768.0000 - mse: 123672608768.0000 - val_loss: 74706870272.0000 - val_mse: 74706870272.0000\n",
      "Epoch 2/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 75914780672.0000 - mse: 75914780672.0000 - val_loss: 74797998080.0000 - val_mse: 74797998080.0000\n",
      "Epoch 3/50\n",
      "346/346 [==============================] - 0s 935us/step - loss: 75100209152.0000 - mse: 75100209152.0000 - val_loss: 70925647872.0000 - val_mse: 70925647872.0000\n",
      "Epoch 4/50\n",
      "346/346 [==============================] - 0s 971us/step - loss: 74548781056.0000 - mse: 74548781056.0000 - val_loss: 76363857920.0000 - val_mse: 76363857920.0000\n",
      "Epoch 5/50\n",
      "346/346 [==============================] - 0s 995us/step - loss: 74764836864.0000 - mse: 74764836864.0000 - val_loss: 70832644096.0000 - val_mse: 70832644096.0000\n",
      "Epoch 6/50\n",
      "346/346 [==============================] - 0s 944us/step - loss: 75377041408.0000 - mse: 75377041408.0000 - val_loss: 68049625088.0000 - val_mse: 68049625088.0000\n",
      "Epoch 7/50\n",
      "346/346 [==============================] - 0s 940us/step - loss: 73425625088.0000 - mse: 73425625088.0000 - val_loss: 68691374080.0000 - val_mse: 68691374080.0000\n",
      "Epoch 8/50\n",
      "346/346 [==============================] - 0s 949us/step - loss: 72815058944.0000 - mse: 72815058944.0000 - val_loss: 67225849856.0000 - val_mse: 67225849856.0000\n",
      "Epoch 9/50\n",
      "346/346 [==============================] - 0s 959us/step - loss: 71536443392.0000 - mse: 71536443392.0000 - val_loss: 65355259904.0000 - val_mse: 65355259904.0000\n",
      "Epoch 10/50\n",
      "346/346 [==============================] - 0s 986us/step - loss: 71163510784.0000 - mse: 71163510784.0000 - val_loss: 65379803136.0000 - val_mse: 65379803136.0000\n",
      "Epoch 11/50\n",
      "346/346 [==============================] - 0s 948us/step - loss: 72618139648.0000 - mse: 72618139648.0000 - val_loss: 64064212992.0000 - val_mse: 64064212992.0000\n",
      "Epoch 12/50\n",
      "346/346 [==============================] - 0s 951us/step - loss: 69456519168.0000 - mse: 69456519168.0000 - val_loss: 77732626432.0000 - val_mse: 77732626432.0000\n",
      "Epoch 13/50\n",
      "346/346 [==============================] - 0s 946us/step - loss: 69745991680.0000 - mse: 69745991680.0000 - val_loss: 63361875968.0000 - val_mse: 63361875968.0000\n",
      "Epoch 14/50\n",
      "346/346 [==============================] - 0s 947us/step - loss: 68736081920.0000 - mse: 68736081920.0000 - val_loss: 65462677504.0000 - val_mse: 65462677504.0000\n",
      "Epoch 15/50\n",
      "346/346 [==============================] - 0s 958us/step - loss: 69454716928.0000 - mse: 69454716928.0000 - val_loss: 75919654912.0000 - val_mse: 75919654912.0000\n",
      "Epoch 16/50\n",
      "346/346 [==============================] - 0s 995us/step - loss: 67658264576.0000 - mse: 67658264576.0000 - val_loss: 62667382784.0000 - val_mse: 62667382784.0000\n",
      "Epoch 17/50\n",
      "346/346 [==============================] - 0s 951us/step - loss: 67036393472.0000 - mse: 67036393472.0000 - val_loss: 59727138816.0000 - val_mse: 59727138816.0000\n",
      "Epoch 18/50\n",
      "346/346 [==============================] - 0s 950us/step - loss: 68071993344.0000 - mse: 68071993344.0000 - val_loss: 63180328960.0000 - val_mse: 63180328960.0000\n",
      "Epoch 19/50\n",
      "346/346 [==============================] - 0s 969us/step - loss: 67679682560.0000 - mse: 67679682560.0000 - val_loss: 60547006464.0000 - val_mse: 60547006464.0000\n",
      "Epoch 20/50\n",
      "346/346 [==============================] - 0s 940us/step - loss: 68256878592.0000 - mse: 68256878592.0000 - val_loss: 59829858304.0000 - val_mse: 59829858304.0000\n",
      "Epoch 21/50\n",
      "346/346 [==============================] - 0s 966us/step - loss: 65899151360.0000 - mse: 65899151360.0000 - val_loss: 63699226624.0000 - val_mse: 63699226624.0000\n",
      "Epoch 22/50\n",
      "346/346 [==============================] - 0s 956us/step - loss: 66403811328.0000 - mse: 66403811328.0000 - val_loss: 58270097408.0000 - val_mse: 58270097408.0000\n",
      "Epoch 23/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 63520088064.0000 - mse: 63520088064.0000 - val_loss: 67468382208.0000 - val_mse: 67468382208.0000\n",
      "Epoch 24/50\n",
      "346/346 [==============================] - 0s 984us/step - loss: 64041500672.0000 - mse: 64041500672.0000 - val_loss: 62355890176.0000 - val_mse: 62355890176.0000\n",
      "Epoch 25/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 63205888000.0000 - mse: 63205888000.0000 - val_loss: 63652179968.0000 - val_mse: 63652179968.0000\n",
      "Epoch 26/50\n",
      "346/346 [==============================] - 0s 961us/step - loss: 62925451264.0000 - mse: 62925451264.0000 - val_loss: 60356812800.0000 - val_mse: 60356812800.0000\n",
      "Epoch 27/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 63681175552.0000 - mse: 63681175552.0000 - val_loss: 62040354816.0000 - val_mse: 62040354816.0000\n",
      "Epoch 28/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 64328409088.0000 - mse: 64328409088.0000 - val_loss: 57643286528.0000 - val_mse: 57643286528.0000\n",
      "Epoch 29/50\n",
      "346/346 [==============================] - 0s 959us/step - loss: 63489474560.0000 - mse: 63489474560.0000 - val_loss: 54888865792.0000 - val_mse: 54888865792.0000\n",
      "Epoch 30/50\n",
      "346/346 [==============================] - 0s 973us/step - loss: 62598402048.0000 - mse: 62598402048.0000 - val_loss: 72210219008.0000 - val_mse: 72210219008.0000\n",
      "Epoch 31/50\n",
      "346/346 [==============================] - 0s 991us/step - loss: 62009651200.0000 - mse: 62009651200.0000 - val_loss: 55006670848.0000 - val_mse: 55006670848.0000\n",
      "Epoch 32/50\n",
      "346/346 [==============================] - 0s 958us/step - loss: 59422154752.0000 - mse: 59422154752.0000 - val_loss: 55321055232.0000 - val_mse: 55321055232.0000\n",
      "Epoch 33/50\n",
      "346/346 [==============================] - 0s 963us/step - loss: 61282746368.0000 - mse: 61282746368.0000 - val_loss: 55512539136.0000 - val_mse: 55512539136.0000\n",
      "Epoch 34/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 58611879936.0000 - mse: 58611879936.0000 - val_loss: 51223937024.0000 - val_mse: 51223937024.0000\n",
      "Epoch 35/50\n",
      "346/346 [==============================] - 0s 993us/step - loss: 62530068480.0000 - mse: 62530068480.0000 - val_loss: 62077390848.0000 - val_mse: 62077390848.0000\n",
      "Epoch 36/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 61180686336.0000 - mse: 61180686336.0000 - val_loss: 52097216512.0000 - val_mse: 52097216512.0000\n",
      "Epoch 37/50\n",
      "346/346 [==============================] - 0s 962us/step - loss: 61250146304.0000 - mse: 61250146304.0000 - val_loss: 51706454016.0000 - val_mse: 51706454016.0000\n",
      "Epoch 38/50\n",
      "346/346 [==============================] - 0s 966us/step - loss: 56810573824.0000 - mse: 56810573824.0000 - val_loss: 49378848768.0000 - val_mse: 49378848768.0000\n",
      "Epoch 39/50\n",
      "346/346 [==============================] - 0s 994us/step - loss: 55303507968.0000 - mse: 55303507968.0000 - val_loss: 55337922560.0000 - val_mse: 55337922560.0000\n",
      "Epoch 40/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 56561065984.0000 - mse: 56561065984.0000 - val_loss: 46249529344.0000 - val_mse: 46249529344.0000\n",
      "Epoch 41/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 56914886656.0000 - mse: 56914886656.0000 - val_loss: 47360606208.0000 - val_mse: 47360606208.0000\n",
      "Epoch 42/50\n",
      "346/346 [==============================] - 0s 981us/step - loss: 55742205952.0000 - mse: 55742205952.0000 - val_loss: 57667674112.0000 - val_mse: 57667674112.0000\n",
      "Epoch 43/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 54258429952.0000 - mse: 54258429952.0000 - val_loss: 45224173568.0000 - val_mse: 45224173568.0000\n",
      "Epoch 44/50\n",
      "346/346 [==============================] - 0s 974us/step - loss: 52477816832.0000 - mse: 52477816832.0000 - val_loss: 43992735744.0000 - val_mse: 43992735744.0000\n",
      "Epoch 45/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 52706881536.0000 - mse: 52706881536.0000 - val_loss: 43462889472.0000 - val_mse: 43462889472.0000\n",
      "Epoch 46/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 52338577408.0000 - mse: 52338577408.0000 - val_loss: 54812491776.0000 - val_mse: 54812491776.0000\n",
      "Epoch 47/50\n",
      "346/346 [==============================] - 0s 970us/step - loss: 49235017728.0000 - mse: 49235017728.0000 - val_loss: 47903158272.0000 - val_mse: 47903158272.0000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 998us/step - loss: 47883239424.0000 - mse: 47883239424.0000 - val_loss: 41656373248.0000 - val_mse: 41656373248.0000\n",
      "Epoch 49/50\n",
      "346/346 [==============================] - 0s 950us/step - loss: 49359835136.0000 - mse: 49359835136.0000 - val_loss: 57971818496.0000 - val_mse: 57971818496.0000\n",
      "Epoch 50/50\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 51909283840.0000 - mse: 51909283840.0000 - val_loss: 39161872384.0000 - val_mse: 39161872384.0000\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train, y_train, epochs = 50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at Epoch 50:\n",
      "\n",
      "loss:51909283840.0\n",
      "\n",
      "mse:51909283840.0\n",
      "\n",
      "val_loss:39161872384.0\n",
      "\n",
      "val_mse:39161872384.0\n",
      "\n",
      "RMSE :197893.58853687\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation at Epoch 50:\\n')\n",
    "for key in history_2.history:\n",
    "    print(key + ':' + str(history_2.history[key][-1]) + '\\n')\n",
    "    \n",
    "print('RMSE :' + str(np.sqrt(history_2.history['val_mse'][-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error here is reduced from the last attempt. This tells us that more layers might have been needed to get a better estimate of the target. The error measured in the validation set gets us over the threshold and achieves our goal of less than 200000. It does not however compare to the original models created. I think the next best step would be to incorporate randomized search to find optimal parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

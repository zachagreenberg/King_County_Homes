{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition of a Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the previous three models for consideration, I decided to go back and take a look at the possibility of adding a fourth model. I wanted to see if I can use a model with Deep Neural Networks for a more realistic assessment of housing prices. I was able to reach my goal of coming under $200000, but I believe that I can do even better with the use of a neural network. I am going to bring in my cleaned data so that I can go right into the modeling process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing in the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in the cleaned\n",
    "infile = open(\"Data/cleaned_data.pickle\",'rb')\n",
    "df = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>log_yard</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2390</td>\n",
       "      <td>8.969287</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1070</td>\n",
       "      <td>2370</td>\n",
       "      <td>8.250620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>9.105868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>9.419628</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2250</td>\n",
       "      <td>8.318986</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  bedrooms  bathrooms  sqft_living  floors  waterfront  \\\n",
       "0   365000.0       4.0        2.0       2070.0     2.0           0   \n",
       "1   865000.0       5.0        3.0       2900.0     1.0           0   \n",
       "2  1038000.0       4.0        2.0       3770.0     2.0           0   \n",
       "3  1490000.0       3.0        4.0       4560.0     2.0           0   \n",
       "4   711000.0       3.0        2.0       2550.0     2.0           0   \n",
       "\n",
       "   sqft_above  sqft_basement  sqft_living15  log_yard  ...  zipcode_98146  \\\n",
       "0      2070.0              0           2390  8.969287  ...              0   \n",
       "1      1830.0           1070           2370  8.250620  ...              0   \n",
       "2      3770.0              0           3710  9.105868  ...              0   \n",
       "3      4560.0              0           4050  9.419628  ...              0   \n",
       "4      2550.0              0           2250  8.318986  ...              0   \n",
       "\n",
       "   zipcode_98148  zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98178  zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0              0  \n",
       "1              0              0              0              0  \n",
       "2              0              0              0              0  \n",
       "3              0              0              0              0  \n",
       "4              0              0              0              0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the dependent variable\n",
    "dvariables = df.iloc[:, 1:]\n",
    "\n",
    "#this here will become the SHAPE variable in the function below\n",
    "number_of_columns = len(dvariables.columns)\n",
    "\n",
    "#isolating the target variable\n",
    "target = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing train test split\n",
    "X_fulltrain, X_fulltest, y_fulltrain, y_fulltest = train_test_split(dvariables, target, random_state = 42, test_size = .2)\n",
    "\n",
    "#splitting again for a validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_fulltrain, y_fulltrain, random_state = 42, test_size = .2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the metric for the model\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"This is a helper function to allow root_mean_squared_error\n",
    "    as the evaluation metric\"\"\"\n",
    "    return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_layers = 1, shape = 106, optimizer = 'adam'):\n",
    "    \"\"\"This function takes in the number of hidden layers, shape of the input, \n",
    "    and the optimizer to create a model ready to be fit.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(shape, activation = 'relu', input_shape=(shape, )))\n",
    "    for layer in range(num_layers):\n",
    "        model.add(keras.layers.Dense(shape, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer, loss = root_mean_squared_error, metrics = [root_mean_squared_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = create_model(2, number_of_columns, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 330225.1562 - root_mean_squared_error: 330162.8750 - val_loss: 251483.4062 - val_root_mean_squared_error: 250923.8125\n",
      "Epoch 2/30\n",
      "346/346 [==============================] - 0s 847us/step - loss: 248199.9219 - root_mean_squared_error: 248139.5312 - val_loss: 250787.8438 - val_root_mean_squared_error: 250155.1094\n",
      "Epoch 3/30\n",
      "346/346 [==============================] - 0s 897us/step - loss: 247274.6875 - root_mean_squared_error: 247268.5781 - val_loss: 253614.4688 - val_root_mean_squared_error: 252929.2812\n",
      "Epoch 4/30\n",
      "346/346 [==============================] - 0s 915us/step - loss: 247934.3750 - root_mean_squared_error: 247900.2969 - val_loss: 249905.2500 - val_root_mean_squared_error: 249272.0469\n",
      "Epoch 5/30\n",
      "346/346 [==============================] - 0s 959us/step - loss: 245667.2500 - root_mean_squared_error: 245694.1562 - val_loss: 250299.6250 - val_root_mean_squared_error: 249647.7188\n",
      "Epoch 6/30\n",
      "346/346 [==============================] - 0s 827us/step - loss: 245377.4688 - root_mean_squared_error: 245427.1250 - val_loss: 249112.2344 - val_root_mean_squared_error: 248487.4531\n",
      "Epoch 7/30\n",
      "346/346 [==============================] - 0s 982us/step - loss: 246975.5000 - root_mean_squared_error: 246954.7969 - val_loss: 249550.4062 - val_root_mean_squared_error: 248893.6094\n",
      "Epoch 8/30\n",
      "346/346 [==============================] - 0s 820us/step - loss: 244754.2812 - root_mean_squared_error: 244724.0469 - val_loss: 251502.8906 - val_root_mean_squared_error: 250969.7969\n",
      "Epoch 9/30\n",
      "346/346 [==============================] - 0s 969us/step - loss: 245872.6094 - root_mean_squared_error: 245870.4688 - val_loss: 247578.3750 - val_root_mean_squared_error: 246950.2500\n",
      "Epoch 10/30\n",
      "346/346 [==============================] - 0s 863us/step - loss: 245478.8281 - root_mean_squared_error: 245477.8438 - val_loss: 247142.6719 - val_root_mean_squared_error: 246544.2500\n",
      "Epoch 11/30\n",
      "346/346 [==============================] - 0s 984us/step - loss: 244984.8750 - root_mean_squared_error: 244928.0469 - val_loss: 247974.7812 - val_root_mean_squared_error: 247313.2812\n",
      "Epoch 12/30\n",
      "346/346 [==============================] - 0s 861us/step - loss: 243999.3906 - root_mean_squared_error: 243984.3906 - val_loss: 246556.6406 - val_root_mean_squared_error: 245920.6875\n",
      "Epoch 13/30\n",
      "346/346 [==============================] - 0s 890us/step - loss: 243346.7344 - root_mean_squared_error: 243354.8594 - val_loss: 245813.8750 - val_root_mean_squared_error: 245238.9375\n",
      "Epoch 14/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 242825.2500 - root_mean_squared_error: 242768.2812 - val_loss: 244993.6250 - val_root_mean_squared_error: 244408.4062\n",
      "Epoch 15/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 241684.0156 - root_mean_squared_error: 241656.2031 - val_loss: 245235.2969 - val_root_mean_squared_error: 244689.7188\n",
      "Epoch 16/30\n",
      "346/346 [==============================] - 0s 858us/step - loss: 241764.2969 - root_mean_squared_error: 241695.3594 - val_loss: 243539.2500 - val_root_mean_squared_error: 242952.4062\n",
      "Epoch 17/30\n",
      "346/346 [==============================] - 0s 926us/step - loss: 240501.3906 - root_mean_squared_error: 240556.2812 - val_loss: 242915.5469 - val_root_mean_squared_error: 242324.0000\n",
      "Epoch 18/30\n",
      "346/346 [==============================] - 0s 864us/step - loss: 240173.4219 - root_mean_squared_error: 240157.0156 - val_loss: 242270.3750 - val_root_mean_squared_error: 241702.0938\n",
      "Epoch 19/30\n",
      "346/346 [==============================] - 0s 964us/step - loss: 240521.3594 - root_mean_squared_error: 240521.6719 - val_loss: 242259.5625 - val_root_mean_squared_error: 241628.1875\n",
      "Epoch 20/30\n",
      "346/346 [==============================] - 0s 834us/step - loss: 239468.6406 - root_mean_squared_error: 239415.7500 - val_loss: 241583.2344 - val_root_mean_squared_error: 240989.5156\n",
      "Epoch 21/30\n",
      "346/346 [==============================] - 0s 925us/step - loss: 238737.7344 - root_mean_squared_error: 238658.5625 - val_loss: 241902.9375 - val_root_mean_squared_error: 241281.9375\n",
      "Epoch 22/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 239087.9688 - root_mean_squared_error: 239129.4062 - val_loss: 243292.8125 - val_root_mean_squared_error: 242649.7188\n",
      "Epoch 23/30\n",
      "346/346 [==============================] - 0s 990us/step - loss: 235970.2656 - root_mean_squared_error: 235933.0000 - val_loss: 238806.2969 - val_root_mean_squared_error: 238262.5938\n",
      "Epoch 24/30\n",
      "346/346 [==============================] - 0s 849us/step - loss: 237163.9062 - root_mean_squared_error: 237143.3750 - val_loss: 238114.6094 - val_root_mean_squared_error: 237585.3281\n",
      "Epoch 25/30\n",
      "346/346 [==============================] - 0s 857us/step - loss: 236657.2031 - root_mean_squared_error: 236667.2656 - val_loss: 238072.5938 - val_root_mean_squared_error: 237550.2812\n",
      "Epoch 26/30\n",
      "346/346 [==============================] - 0s 940us/step - loss: 234188.5156 - root_mean_squared_error: 234162.5156 - val_loss: 238548.9375 - val_root_mean_squared_error: 238065.6250\n",
      "Epoch 27/30\n",
      "346/346 [==============================] - 0s 853us/step - loss: 233978.3750 - root_mean_squared_error: 233994.6406 - val_loss: 235566.1719 - val_root_mean_squared_error: 235051.1719\n",
      "Epoch 28/30\n",
      "346/346 [==============================] - 0s 850us/step - loss: 231976.9219 - root_mean_squared_error: 232057.4375 - val_loss: 234794.9219 - val_root_mean_squared_error: 234196.8281\n",
      "Epoch 29/30\n",
      "346/346 [==============================] - 0s 950us/step - loss: 231740.4062 - root_mean_squared_error: 231761.7500 - val_loss: 236001.6719 - val_root_mean_squared_error: 235516.9688\n",
      "Epoch 30/30\n",
      "346/346 [==============================] - 0s 827us/step - loss: 231196.3594 - root_mean_squared_error: 231147.6094 - val_loss: 240313.7969 - val_root_mean_squared_error: 239650.1094\n"
     ]
    }
   ],
   "source": [
    "#fitting the model\n",
    "history = model_1.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid)) #creating a small validation set to assess overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at Epoch 50:\n",
      "\n",
      "loss:231196.359375\n",
      "\n",
      "root_mean_squared_error:231147.609375\n",
      "\n",
      "val_loss:240313.796875\n",
      "\n",
      "val_root_mean_squared_error:239650.109375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation at Epoch 50:\\n')\n",
    "for key in history.history:\n",
    "    print(key + ':' + str(history.history[key][-1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see here that the train set and validation set have come very close to one another. In terms of the actual metric the model has not crossed the threshold of the goal RMSE. For now I am led to believe that the original chosen model shows the most promise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an attempt at improvement, I am going to try another model with more layers to see how that would compare to the first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = create_model(8, number_of_columns, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 285562.0312 - root_mean_squared_error: 285577.7188 - val_loss: 250583.3906 - val_root_mean_squared_error: 250043.5156\n",
      "Epoch 2/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 248650.8906 - root_mean_squared_error: 248634.9531 - val_loss: 262819.4688 - val_root_mean_squared_error: 262472.2188\n",
      "Epoch 3/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 248696.8438 - root_mean_squared_error: 248829.2500 - val_loss: 245773.5781 - val_root_mean_squared_error: 245259.4062\n",
      "Epoch 4/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 248977.8281 - root_mean_squared_error: 249004.8750 - val_loss: 262547.4062 - val_root_mean_squared_error: 261914.3906\n",
      "Epoch 5/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 246389.7656 - root_mean_squared_error: 246353.7344 - val_loss: 248316.8125 - val_root_mean_squared_error: 247756.9375\n",
      "Epoch 6/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 245873.2812 - root_mean_squared_error: 245822.6562 - val_loss: 243323.8906 - val_root_mean_squared_error: 242892.7969\n",
      "Epoch 7/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 245618.9219 - root_mean_squared_error: 245560.6406 - val_loss: 249401.9375 - val_root_mean_squared_error: 249075.2188\n",
      "Epoch 8/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 242584.6562 - root_mean_squared_error: 242528.2031 - val_loss: 242312.5625 - val_root_mean_squared_error: 241915.6094\n",
      "Epoch 9/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 240865.7344 - root_mean_squared_error: 240868.1094 - val_loss: 263584.3438 - val_root_mean_squared_error: 263328.4375\n",
      "Epoch 10/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 240629.2656 - root_mean_squared_error: 240586.5938 - val_loss: 247238.0312 - val_root_mean_squared_error: 246688.0000\n",
      "Epoch 11/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 239596.0156 - root_mean_squared_error: 239530.7812 - val_loss: 245053.9219 - val_root_mean_squared_error: 244482.0000\n",
      "Epoch 12/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 241868.5000 - root_mean_squared_error: 241928.6406 - val_loss: 234388.7656 - val_root_mean_squared_error: 233892.8906\n",
      "Epoch 13/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 238201.1562 - root_mean_squared_error: 238167.5156 - val_loss: 238218.2031 - val_root_mean_squared_error: 237644.1094\n",
      "Epoch 14/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 234584.0312 - root_mean_squared_error: 234593.4375 - val_loss: 238357.2344 - val_root_mean_squared_error: 237799.9062\n",
      "Epoch 15/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 232478.0312 - root_mean_squared_error: 232454.8438 - val_loss: 238784.8281 - val_root_mean_squared_error: 238370.1562\n",
      "Epoch 16/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 236551.0781 - root_mean_squared_error: 236508.0000 - val_loss: 226365.5938 - val_root_mean_squared_error: 225733.2812\n",
      "Epoch 17/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 231763.3125 - root_mean_squared_error: 231703.9062 - val_loss: 225130.6250 - val_root_mean_squared_error: 224507.7500\n",
      "Epoch 18/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 228903.7969 - root_mean_squared_error: 228880.9219 - val_loss: 222629.1406 - val_root_mean_squared_error: 221888.2500\n",
      "Epoch 19/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 227445.9531 - root_mean_squared_error: 227490.5625 - val_loss: 226726.6719 - val_root_mean_squared_error: 226048.4375\n",
      "Epoch 20/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 224716.0625 - root_mean_squared_error: 224709.1719 - val_loss: 215976.3594 - val_root_mean_squared_error: 215305.2188\n",
      "Epoch 21/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 218916.5312 - root_mean_squared_error: 218917.8906 - val_loss: 219143.6719 - val_root_mean_squared_error: 218612.3750\n",
      "Epoch 22/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 220731.3906 - root_mean_squared_error: 220683.9844 - val_loss: 219477.1250 - val_root_mean_squared_error: 218812.4844\n",
      "Epoch 23/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 217707.8906 - root_mean_squared_error: 217653.2188 - val_loss: 208090.4219 - val_root_mean_squared_error: 207328.3750\n",
      "Epoch 24/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 214525.9844 - root_mean_squared_error: 214478.3750 - val_loss: 211051.3906 - val_root_mean_squared_error: 210539.8594\n",
      "Epoch 25/30\n",
      "346/346 [==============================] - 1s 1ms/step - loss: 209774.0156 - root_mean_squared_error: 209740.2344 - val_loss: 209572.7812 - val_root_mean_squared_error: 208880.4375\n",
      "Epoch 26/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 207702.5312 - root_mean_squared_error: 207650.9062 - val_loss: 218523.5781 - val_root_mean_squared_error: 218138.9844\n",
      "Epoch 27/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 206153.0625 - root_mean_squared_error: 206161.9375 - val_loss: 200285.4375 - val_root_mean_squared_error: 199786.4844\n",
      "Epoch 28/30\n",
      "346/346 [==============================] - 0s 1ms/step - loss: 198463.8281 - root_mean_squared_error: 198426.7031 - val_loss: 194678.5938 - val_root_mean_squared_error: 194097.9844\n",
      "Epoch 29/30\n",
      "346/346 [==============================] - 1s 1ms/step - loss: 199301.6562 - root_mean_squared_error: 199304.2500 - val_loss: 188957.8438 - val_root_mean_squared_error: 188376.3125\n",
      "Epoch 30/30\n",
      "346/346 [==============================] - 1s 1ms/step - loss: 190927.1406 - root_mean_squared_error: 190863.5781 - val_loss: 189786.8906 - val_root_mean_squared_error: 189243.8750\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at Epoch 50:\n",
      "\n",
      "loss:190927.140625\n",
      "\n",
      "root_mean_squared_error:190863.578125\n",
      "\n",
      "val_loss:189786.890625\n",
      "\n",
      "val_root_mean_squared_error:189243.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation at Epoch 50:\\n')\n",
    "for key in history_2.history:\n",
    "    print(key + ':' + str(history_2.history[key][-1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error here is reduced in addition to the validation set performing better. This tells us that there's no overfitting, and more layers were needed to get a better estimate of the target. There is an issue of slight overfitting, even with a validation set. I think the next best step would be to incorporate random search to find optimal parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
